\documentclass[11pt,letterpaper]{article}
\usepackage{naaclhlt2015}
\usepackage{times}
\usepackage{latexsym}
% \setlength\titlebox{6.5cm}    % Expanding the titlebox

\newcommand{\ccgsyn}[1]{\ensuremath{#1}}

% Alternative titles:
% Modeling Intension and Extension in Neural Networks for Grounded Language Understanding
\title{Unifying Logical Semantics and Neural Networks by \\ Representing Intension and Extension}

\author{Author 1\\
	    XYZ Company\\
	    111 Anywhere Street\\
	    Mytown, NY 10000, USA\\
	    {\tt author1@xyz.org}
	  \And
	Author 2\\
  	ABC University\\
  	900 Main Street\\
  	Ourcity, PQ, Canada A1A 1T2\\
  {\tt author2@abc.ca}}

\date{}

\begin{document}
\maketitle
\begin{abstract}
TODO
\end{abstract}

\section{Introduction}

The field of natural language semantics is divided between two kinds
of approaches: \emph{logical} approaches such as semantic parsing, and
\emph{vector space} approaches, including neural networks. There remains
significant confusion about the benefits and drawbacks of each
approach, with logical practitioners wondering how neural networks can
represent complex phenomena that can be easily represented in logic,
such as quantification. While some work has attempted to combine both
approaches in a single framework (TODO: citations), this work has
largely avoided the essential question: \emph{can neural networks
reproduce a logical semantics}?

% Neural networks and other vector space approaches to semantics are
% often contrasted with model-theoretic approaches based on logical
% queries against knowledge bases. This paper demonstrates that a
% properly structured neural network can learn to predict a
% model-theoretic semantics for language, identical to the semantics
% produced by a logical representation.

This paper answers the above question in the affirmative. We present a
novel neural network architecture that can learn a model-theoretic
semantics for language, that is, the network can learn to map from
text to denotations. The network is capable of representing many
linguistic phenomena, including object references, relationships, and
generalized quantifiers. Our architecture has strong theoretical
motivation from logical semantics and approximate query evaluation
algorithms for probabilistic databases. These connections explain why
the proposed network structure is capable of learning a
model-theoretic semantics. We also present empirical evidence on
several grounded language understanding tasks.

% We implement our neural network using the
% \emph{vector space semantic parsing} framework (TODO), which  This framework
% uses Combinatory Categorial Grammar to define the structure of the
% neural network, enabling a powerful and non-uniform parameterization.

The key insight of this work is to explicitly represent both the
intensional and extensional meanings of language within the neural
network. The \emph{intension} of a text is a context-independent value
that (TODO); in contrast, the \emph{extension} is the set of
real-world entities (or events, etc.) denoted by the text. (TODO:
example). Prior work on compositional semantics using vector space
models can be viewed as representing the intension of a text, as the
vectors produced by these models do not depend on the environment in
which the text was understood. However, it is unclear how to derive a
model-theoretic semantics by composing these intensional meanings. In
contrast, we explicitly represent extensional meaning in our neural
network, which enables our network to almost directly map on to
logical semantics.

We evaluate our approach on two grounded language understanding tasks
(TODO: citations), where the goal is to map natural language
descriptions (or questions) to their referents (or answers) in an
environment. On these tasks, our neural network approach achieves
comparable performance to state-of-the-art approaches that are
considerably more computationally intensive. We further demonstrate
that previously proposed neural network approaches that only represent
intensional meaning perform poorly on these tasks.


\section{Approach}

\subsection{Problem Definition}

This paper considers the problem of grounded language
understanding. The input to this problem is an environment $d$
containing a set of entities $e \in E_d$, and a natural language text
$z$.  The goal of the task is to predict a \emph{denotation}
$\gamma \subseteq E_d$ for the text.\footnote{For simplicity, we
assume the denotation is a set of entities and not a truth
value. However, it is simple to modify our approach to also predict
truth values.} If $z$ is a noun phrase, $\gamma$ is its entity
referents; if $z$ is a question, $\gamma$ is its answer. TODO: figure
showing one example from each of our data sets.

\subsection{Network Architecture}

Our network architecture is designed to closely simulate the
operations performed when evaluating a logical form against a
knowledge base. Given a text $z$, the network assigns an intension
vector to each word in the text. This intension can be viewed as
equivalent to a predicate in a logical semantics, in that it is a
function from environments to sets of entities. Next, the network maps
each word's intension to an extension, which is a vector or matrix
representing the entity referents of the word. Finally, the network
takes these extensions and composes them to simulate the set
operations performed on extensions within logical semantics. Many of
these operations can be exactly replicated using arithmetic operations
(e.g., conjunction is elementwise multiplication), while others can be
approximately replicated (e.g., existential quantification is addition
with a sigmoid).

Note that the structure of the network must vary considerably from
sentence to sentence. We implement our neural network using the vector
space semantic parsing framework (TODO: citation). This framework uses
Combinatory Categorial Grammar (CCG) to define a correspondence
between syntactic categories and semantic representations, which are
vectors and functions on vectors.

\begin{table*}
\begin{tabular}{llll}
Words & Syntactic Categories & VSSP logical form & Logical semantics \\
* & \ccgsyn{N} & $v_{word}$ & $\lambda x.word(x)$ \\
* & \ccgsyn{N/N} & $\lambda f. v_{word} + f$ & $\lambda f.\lambda x. f(x) \wedge word(x)$ \\
* & \ccgsyn{(S\backslash N)/N}, \ccgsyn{(N\backslash N)/N} & $\lambda f. \lambda g. g + A_{word} f$ & $\lambda f. \lambda g. \lambda x. g(x) \wedge \exists y. word(x, y) \wedge f(y)$ \\
is,are,was & \ccgsyn{(S\backslash N)/N} & $\lambda f. \lambda g. g + f$ & $\lambda f. \lambda g. \lambda x. g(x) \wedge f(x)$ \\
\end{tabular}

\caption{$v_word = \Phi_{cat}(E_d) category intension word$, $A_word = \Phi_{rel}(E_d) relation intension word$}
\end{table*}

The structure of our network has a close connection to 

Approach
- Problem definition
- Vector space semantic parsing
- Network Structure
- Connection 

Prior work
- show that matuszek, malinowski, and my own work largely fits in this paradigm
- explain relationship to Sam's (stanford) logical semantics thing
- explain relationship to mooney's inference stuff.
- matt gormley and jason eisner - backpropagating through inference algorithm

Discussion

What can't we represent in our network?
-- Modeling beliefs -- requires an explicit representation of intension


Interesting experiments
- low dimensional embeddings of sets of entities
- other data sets (geoQA and the malinowski one)
- synthetic quantifier data

\end{document}
