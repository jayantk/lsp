#!/bin/bash

# $1 is a domain directory where the output entity features, all-pairs grep results, etc.
# will be placed. The "locations.txt" file in this directory determines the entities which
# are included in the data.

LOCATION_INPUT_FILE=$1/locations.txt

OSM_TEMP_FILE=$1/temp.locations.osm
LOCATION_TEMP_FILE=$1/temp.locations.allpairs

CATEGORY_ALL_PAIRS_FILE=/nell/data/all-pairs-dir/all-pairs-OC-2011-11-14-big2-gz/cat_pairs_np-idx.txt.gz
RELATION_ALL_PAIRS_FILE=/nell/data/all-pairs-dir/all-pairs-OC-2011-11-14-big2-gz/rel_pairs_np-idx.txt.gz

CAT_APG_OUT=$1/cat_out.txt
REL_APG_OUT=$1/rel_out.txt

# Where to download the openstreetmap entities.
OSM_DIR=$1/osm/
OSM_DOWNLOAD_SCRIPT=/home/jayantk/tkollar/pytools/openstreetmap/python/osm/bin/download_places.py

# Where to store the features generated by each view of the data.
CAT_FEATURES_FILE=$1/osm_kb.domain.entities
CAT_WORD_FEATURES_FILE=$1/osm_kb.words.entities
REL_FEATURES_FILE=$1/osm_kb.domain.relations
REL_WORD_FEATURES_FILE=$1/osm_kb.words.relations

GEO_FEATURES_FILE_PREFIX=$1/osm_kb.geo
CAT_GEO_FEATURES_FILE=$1/osm_kb.geo.entities
REL_GEO_FEATURES_FILE=$1/osm_kb.geo.relations

# How many all-pairs features to generate for the category and relation classifiers.
NUM_CATEGORY_FEATURES=20
CAT_MIN_FEATURE_OCCURRENCE=2
NUM_RELATION_FEATURES=20
REL_MIN_FEATURE_OCCURRENCE=2

# Auto-generated files containing the domain's entities.
ENTITY_LEXICON_FILE=$1/lexicon.entities.txt
ENTITY_BASELINE_LEXICON_FILE=$1/baseline_lexicon.entities.txt
ENTITY_TRAINING_FILE=$1/training.entities.txt
USER_TRAINING_DATA=$1/training.questions.txt
OBSERVED_TRAINING_DATA=$1/training.fullylabeled.txt
FINAL_TRAINING_DATA=$1/training.txt
OBSERVED_BASELINE_TRAINING_DATA=$1/training_observed_baseline.txt

GENERATED_LEXICON_FILE=$1/lexicon.genlex.txt
GENERATED_BASELINE_LEXICON_FILE=$1/baseline_lexicon.genlex.txt
DOMAIN_LEXICON=$1/lexicon.txt
DOMAIN_BASELINE_LEXICON=$1/baseline_lexicon.txt
DOMAIN_LEXICON_PATTERN=$(dirname "$1")"/**/lexicon.txt"
DOMAIN_BASELINE_LEXICON_PATTERN=$(dirname "$1")"/**/baseline_lexicon.txt"
CROSS_DOMAIN_LEXICON=$(dirname "$1")"/lexicon.txt"
CROSS_DOMAIN_BASELINE_LEXICON=$(dirname "$1")"/baseline_lexicon.txt"

# Where to put the KB containing basic precomputed predicates.
KB_CATEGORY_FILE=$1/kb.txt.categories
KB_RELATION_FILE=$1/kb.txt.relations

WORD_HISTO_FILE=$1/word_histogram.txt

# cat $LOCATION_INPUT_FILE | sed 's/\([^;]*\);.*$/\1/g' > $LOCATION_TEMP_FILE
# cat $LOCATION_INPUT_FILE | sed 's/\([^;]*\);\([^;]*\);.*/\2/g' > $OSM_TEMP_FILE
# 
# if [ ! -f $CAT_APG_OUT ];
# then
#     echo "Grepping Category All-Pairs..."
#     ./src/scripts/invoke.pl AllPairsGrep $CATEGORY_ALL_PAIRS_FILE $LOCATION_TEMP_FILE $CAT_APG_OUT
# else 
#     echo "$CAT_APG_OUT already exists. Not regenerating."
# fi
# 
# if [ ! -f $REL_APG_OUT ];
# then
#     echo "Grepping Relation All-Pairs..."
#     ./src/scripts/invoke.pl RelationAllPairsGrep $RELATION_ALL_PAIRS_FILE $LOCATION_TEMP_FILE $REL_APG_OUT
# else
#     echo "$REL_APG_OUT already exists. Not regenerating."
# fi
# 
# if [ ! -d $OSM_DIR ];
# then
#    echo "Downloading OSM entities"
#    echo "   Creating directory $OSM_DIR"
#    mkdir $OSM_DIR
#    python $OSM_DOWNLOAD_SCRIPT $OSM_TEMP_FILE $OSM_DIR
# else
#    echo "$OSM_DIR already contains OSM entities. Not regenerating."
# fi
# 
# if [ ! -f $CAT_WORD_FEATURES_FILE ];
# then
#     echo "Generating category word features..."
#     ./src/scripts/cobot/language_geography/count_threshold_all_pairs.py $CAT_APG_OUT $LOCATION_TEMP_FILE $NUM_CATEGORY_FEATURES $CAT_MIN_FEATURE_OCCURRENCE | sort > $CAT_WORD_FEATURES_FILE
# else
#     echo "Category word features already exist. Not regenerating."
# fi
# 
# if [ ! -f $REL_WORD_FEATURES_FILE ];
# then
#     echo "Generating relation word features..."
#     ./src/scripts/cobot/language_geography/count_threshold_all_pairs.py $REL_APG_OUT $LOCATION_TEMP_FILE $NUM_RELATION_FEATURES $REL_MIN_FEATURE_OCCURRENCE | sort > $REL_WORD_FEATURES_FILE
# else
#     echo "Relation word features already exist. Not regenerating."
# fi
# 
# if [ ! -f $CAT_GEO_FEATURES_FILE  -o  ! -f $REL_GEO_FEATURES_FILE ];
# then
#     echo "Generating geo features..."
#     CUR_DIR=`pwd`
#     FULL_DOMAIN_PATH=$(readlink -f $1)
#     cd /home/jayantk/tkollar/pytools/openstreetmap/
#     rake create_language_geo_dataset DOMAIN=$FULL_DOMAIN_PATH
#     cd $CUR_DIR
# else
#     echo "geo features already exist. Not regenerating."
# fi
# 
# echo "Joining word and geo category features, standardizing..."
# TEMP_FILE=`tempfile`
# cat $CAT_WORD_FEATURES_FILE $CAT_GEO_FEATURES_FILE | sort > $TEMP_FILE
# cat $TEMP_FILE > $CAT_FEATURES_FILE
# echo "Joining word and geo relation features, standardizing..."
# cat $REL_WORD_FEATURES_FILE $REL_GEO_FEATURES_FILE | sort | grep -v ',0.0$' > $TEMP_FILE 
# cat $TEMP_FILE > $REL_FEATURES_FILE
# rm $TEMP_FILE
# 
# echo "Generating entity lexicon..."
# ./src/scripts/cobot/language_geography/generate_lexicon.py $LOCATION_INPUT_FILE > $ENTITY_LEXICON_FILE
# ./src/scripts/cobot/language_geography/generate_lexicon.py $LOCATION_INPUT_FILE cat > $ENTITY_BASELINE_LEXICON_FILE
# 
# echo "Running genlex on $USER_TRAINING_DATA..."
# TEMP_FILE=`tempfile`
# cat $USER_TRAINING_DATA | sed 's/;.*/ ./g' > $TEMP_FILE
# ./src/scripts/cobot/genlex.sh $TEMP_FILE $GENERATED_LEXICON_FILE $GENERATED_BASELINE_LEXICON_FILE noNNP
# rm $TEMP_FILE
# 
# echo "Combining lexicons from all domains into $CROSS_DOMAIN_LEXICON"
# cat $GENERATED_LEXICON_FILE | grep -v '^[^,]*[A-Z][^,]*,' > $DOMAIN_LEXICON
# cat $ENTITY_LEXICON_FILE >> $DOMAIN_LEXICON
# cat $DOMAIN_LEXICON_PATTERN | sort | uniq > $CROSS_DOMAIN_LEXICON
# 
# echo "Combining baseline lexicons from all domains into $CROSS_DOMAIN_BASELINE_LEXICON"
# cat $GENERATED_BASELINE_LEXICON_FILE | grep -v '^[^,]*[A-Z][^,]*,' > $DOMAIN_BASELINE_LEXICON
# cat $ENTITY_BASELINE_LEXICON_FILE >> $DOMAIN_BASELINE_LEXICON
# cat $DOMAIN_BASELINE_LEXICON_PATTERN | sort | uniq > $CROSS_DOMAIN_BASELINE_LEXICON

echo "Combining training data..."
cat $USER_TRAINING_DATA > $FINAL_TRAINING_DATA
cat $OBSERVED_TRAINING_DATA > $OBSERVED_BASELINE_TRAINING_DATA
#cat $FINAL_TRAINING_DATA | sed 's/^\(.*\);[^;]*;\(.*\)$/\1;1;\2/' >> $OBSERVED_BASELINE_TRAINING_DATA
cat $FINAL_TRAINING_DATA >> $OBSERVED_BASELINE_TRAINING_DATA

# echo "Constructing word histogram..."
# cat $USER_TRAINING_DATA | grep -v '^#' | sed 's/;.*//g' | sed 's/ /\n/g' | sort | uniq -c | sort -g -r > $WORD_HISTO_FILE
# 
# echo "Generating basic kb..."
# ./src/scripts/cobot/language_geography/generate_cat_kb.py $CAT_FEATURES_FILE | sort | uniq > $KB_CATEGORY_FILE
# cut -f1 -d',' $CAT_FEATURES_FILE | sed 's/\(.*\)/kb-equal,\1,\1,T,1/' | sort | uniq > $KB_RELATION_FILE

